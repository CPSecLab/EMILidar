<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>


<head>
    <script src="http://www.google.com/jsapi" type="text/javascript"></script>
    <script type="text/javascript">google.load("jquery", "1.3.2");</script>

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/css/bootstrap.min.css">
      <!-- Custom styles for this template -->
        
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.4.0/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.0/js/bootstrap.min.js"></script>
    <!-- <link rel="icon" href="img/lightcommands.png"> -->
</head>
<style type="text/css">
    body {
        font-family: "Titillium Web", "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight: 300;
        font-size: 17px;
        margin-left: auto;
        margin-right: auto;
        width: 70%;
    }

    h1 {
        font-weight: 300;
        line-height: 1.15em;
    }

    h2 {
        font-size: 2em;
    }

    a:link, a:visited {
        color: #00aeff;
        text-decoration: none;
    }

    a:hover {
        color: #208799;
    }


    b:link, b:visited {
        color: #00aeff;
        text-decoration: none;
    }

    b:hover {
        color: #208799;
    }

    h1, h2, h3 {
        text-align: center;
    }

    h1 {
        font-size: 40px;
        font-weight: 500;
    }

    h2 {
        font-weight: 400;
        margin: 16px 0px 4px 0px;
    }

    .paper-title {
        padding: 16px 0px 16px 0px;
    }

    section {
        margin: 32px 0px 32px 0px;
        text-align: justify;
        clear: both;
    }

    .col-5 {
        width: 20%;
        float: left;
    }

    .col-4 {
        width: 25%;
        float: left;
    }

    .col-3 {
        width: 33%;
        float: left;
    }

    .col-2 {
        width: 50%;
        float: left;
    }

    .col-1 {
        width: 100%;
        float: left;
    }

    .row, .author-row, .affil-row {
        overflow: auto;
    }

    .author-row, .affil-row {
        font-size: 26px;
    }

    .row {
        margin: 16px 0px 16px 0px;
    }

    .authors {
        font-size: 26px;
    }

    .affil-row {
        margin-top: 16px;
    }

    .teaser {
        max-width: 100%;
    }

    .text-center {
        text-align: center;
    }

    .screenshot {
        width: 80%;
        border: 1px solid #ddd;
    }

    .screenshot-el {
        margin-bottom: 1px;
    }

    hr {
        height: 1px;
        border: 0;
        border-top: 1px solid #ddd;
        margin: 0;
    }

    .material-icons {
        vertical-align: -6px;
    }

    p {
        line-height: 1.25em;
    }

    .caption {
        font-size: 16px;
        /*font-style: italic;*/
        color: #666;
        text-align: center;
        margin-top: 4px;
        margin-bottom: 10px;
    }

    video {
        display: block;
        margin: auto;
    }

    figure {
        display: block;
        margin: auto;
        margin-top: 10px;
        margin-bottom: 10px;
    }

    #bibtex pre {
        font-size: 13.5px;
        background-color: #eee;
        padding: 16px;
    }

    .blue {
        color: #2c82c9;
        font-weight: bold;
    }

    .orange {
        color: #d35400;
        font-weight: bold;
    }

    .flex-row {
        display: flex;
        flex-flow: row wrap;
        justify-content: space-around;
        padding: 0;
        margin: 0;
        list-style: none;
    }
    .table {
	width:100%;
	border:1px solid color-form-highlight;
    }
    
    .table-header {
    	display:flex;
    	width:100%;
    	background:rgb(32, 126, 181);
    	padding:(half-spacing-unit * 1.5) 0;
    }
    
    .table-row {
    	display:flex;
    	width:100%;
    	padding:(half-spacing-unit * 1.5) 0;
    
    }
    
    .table-data, .header__item {
    	flex: 1 1 20%;
    	text-align:center;
    }

    .line{
        border-left-width: 1px;
        border-left-style: solid;
        border-left-color: rgb(92, 84, 84);
    }

    .stack{
        display: block !important;
        width: auto;
    }
    
    .header__item {
    	text-transform:uppercase;
    }

    .paper-btn {
        position: relative;
        text-align: center;

        display: inline-block;
        margin: 8px;
        padding: 8px 8px;

        border-width: 0;
        outline: none;
        border-radius: 2px;

        background-color: #48b64e;
        color: white !important;
        font-size: 20px;
        width: 100px;
        font-weight: 600;
    }

    .paper-btn-parent {
        display: flex;
        justify-content: center;
        margin: 16px 0px;
    }

    .paper-btn:hover {
        opacity: 0.85;
    }

    .container {
        margin-left: auto;
        margin-right: auto;
        padding-left: 16px;
        padding-right: 16px;
    }
    .boxed {
				padding: 0.5em 2em 2em 2em;
				background-color: #F8F8F8;
	
				max-width: 90%;
				margin: 0 auto !important; 
				float: none !important; ;
	}
	.boxed_mini {
				padding: 0.5em 0.5em 0.5em 0.5em;
				max-width: 40%;
				background-color: #ECF9FF;
				
	}

    .venue {
        /*color: #B6486F;*/
        font-size: 30px;

    }

    .myButton_l {
				display:inline-block;
				cursor:pointer;
				font-family: Montserrat,sans-serif;
				font-weight: bold;
				font-size:15px;
				letter-spacing: 0.1em;
				padding:10px 10px;
				text-decoration:none;
			}
	.myButton {
				 background-color:#87d4f5;
				-moz-border-radius:18px;
				-webkit-border-radius:18px;
				border-radius:18px;
				display:inline-block;
				cursor:pointer;
				color:#ffffff;
				font-family: Montserrat,sans-serif;
				font-weight: bold;
				font-size:25px;
				letter-spacing: 0.1em;
				padding:10px 50px;
				text-decoration:none;
			}
	.myButton:hover {
				background-color:#478fcc;
				color:#ffffff;
				
			} 

</style>

<!-- End : Google Analytics Code-->
<script type="text/javascript" src="../js/hidebib.js"></script>
<!-- <link href='https://fonts.googleapis.com/css?family=Titillium+Web:400,600,400italic,600italic,300,300italic'
      rel='stylesheet' type='text/css'> -->
<head>
    <title>EMI-LiDAR: Uncovering Vulnerabilities of LiDAR Sensors in Autonomous Driving Setting using Electromagnetic Interference</title>
    <meta property="og:description" content="EMI-LiDAR: Uncovering Vulnerabilities of LiDAR Sensors in Autonomous Driving Setting using Electromagnetic Interference"/>
    <link href="https://fonts.googleapis.com/css2?family=Material+Icons" rel="stylesheet">

</head>

<body>
<div class="flex-row">
    <div class="paper-title">
        <h1 style="color:rgb(71, 132, 216)"><strong>EMI-LiDAR: Uncovering Vulnerabilities of LiDAR Sensors in Autonomous Driving Setting using Electromagnetic Interference</strong></h1>
    </div>

    <div id="authors">
        <center>
            <div class="author-row">
                <div class="col-3 text-center"><span style="font-size:25px">S. Hrushikesh Bhupathiraju</span><sup>1</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Jennifer Sheldon</span><sup>1</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Luke A. Bauer</span><sup>1</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Vincent Bindschaedler</span><sup>1</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Takeshi Sugawara</span><sup>2</sup></div>
                <div class="col-3 text-center"><span style="font-size:25px">Sara Rampazzi</span><sup>1</sup></div>
            </div>
            <br>
            <div class="text-left mt-auto" style="width:100%;margin-top: 1.5em; margin-bottom: 1.5em; display:flex;justify-content:space-around;align-items:center; flex-wrap: wrap;">
                <div>
                    <a href="https://www.eng.ufl.edu/">
                      <img width = "320px" src="img/uf_logo.PNG" alt="University of Florida logo" class="img-fluid" />
                  <div style = "height:10px"></div>
                    </a>
                    </div>
                    <div>
                    <a href="https://www.uec.ac.jp/eng/">
                      <img width="350px" src="img/uec_logo.png" alt="UEC logo" class="img-fluid" />
                      <div style = "height:10px"></div>
                </a>
                </div>
                </div>
            <!-- <center>
                <br><br>
                <table align=center width=800px>
                    <tr>
                        <td align=center width=300px>
                            <center>
                                <span style="font-size:15px"><sup>1</sup> University of Florida</span>
                            </center>

                        </td>
                        <td align=center width=300px>
                            <center>
                                <span style="font-size:15px"><sup>2</sup> University of Michigan</span>
                            </center>
                        </td>
                        <td align=center width=300px>
                            <center>
                                <span style="font-size:15px"><sup>3</sup> The University of Electro-Communications (Tokyo)</span>
                            </center>
                        </td>
                    </tr>
                </table>
            </center>

        </center> -->
        
    </div>

    <section id="abstract"/>
    <h2> EMI Vulnerability Overview</h2>
    <hr>
    <div class="flex-row">
        <p>
            <br>
            Autonomous Vehicles (AVs) using LiDAR-based object detection systems are rapidly improving and becoming an increasingly viable method of transportation. While effective at perceiving the surrounding environment,  these detection systems are shown to be vulnerable to attacks using lasers which can cause obstacle misclassifications or removal. These laser attacks, however, are challenging to perform, requiring precise aiming and accuracy. Our research exposes a new threat in the form of Intentional Electro-Magnetic-Interference (IEMI), which affects the time-of-flight (TOF) circuits that make up modern LiDARs.
        </p>
    </div>

    <figure style="margin-top: 10px; margin-bottom: 10px;">
        <center><img width="50%" src="./img/emi_overview.png" style="margin-bottom: 20px;"></center>
    </figure>
    <div class="flex-row">
        <p>
             We show that these vulnerabilities can be exploited to force the AV Perception system to misdetect, misclassify objects, and perceive non-existent obstacles. We evaluate the vulnerability in three AV perception modules (PointPillars, PointRCNN, and Apollo) and show how the classification rate drops below 50%. We also analyze the impact of the IEMI injection on two fusion models (AVOD and Frustum-ConvNet) and in real-world scenarios. Finally, we discuss potential countermeasures and propose two strategies to detect signal injection.   </p>
    </div>
    <p class="my-4">To appear in <a href="https://wisec2023.surrey.ac.uk/">ACM WiSec 2023<br><br></a></p>
				
						<center>			
                            <a href="https://arxiv.org/pdf/2210.09482.pdf" class="myButton">Read the Paper</a>
						
			
			
						<!-- <a href="#bibtex"  class=" myButton " data-toggle="collapse" role="button"><span class="material-icons"> insert_comment </span>
					Cite <i class="fa fa-quote-right" aria-hidden="true"></i></a>
						<div id="bibtex" style="margin-top: 1.5em;" class="collapse" align="left">
							<pre style="white-space: pre">

@inproceedings{bhupathiraju2023emiLiDAR,
  title={EMI-LiDAR: Uncovering Vulnerabilities of LiDAR Sensors in Autonomous Driving Setting using Electromagnetic Interference},
  author={Sri Hrushikesh Varma Bhupathiraju, Jennifer Sheldon, Luke A. Bauer, Vincent Bindschaedler, Takeshi Sugawara, Sara Rampazzi},
  booktitle={16th ACM Conference on Security and Privacy in Wireless and Mobile Networks (ACM WiSec 2023)},
  year={2023}
} -->
</center>
							</pre>
						
				</div>	
    </section>

    <section id="novelties"/>
    <h2>IEMI Vulnerability Characterization</h2>
    <hr>
    <div class="flex-row">
        <p>
            <br>
            To determine whether the VLP-16 LiDAR is vulnerable to IEMI, we perform a frequency sweep between 400 MHz and 1 GHz. We found that different frequencies produced different perturbation patterns. We hypothesize that the vulnerability is caused by IEMI-induced voltages surpassing detection thresholds in the LiDAR's ToF circuits. 
        </p>
    </div>
	
	<div class="col-3 text-center"> <figure style="width: 100%">
        <center><img width="100%" src="vid/NoAttackGif.gif"></center>
		<div class="overlayText">
                <br>
            </div>
       
    </figure>
    </div>
    <div class="col-3 text-center"> <figure style="width: 100%">
        <center><img width="100%" src="vid/SineGif.gif"></center>
        <div class="overlayText">
                <br>
            </div>
       
    </figure>
    </div>
        <div class="col-3 text-center"> <figure style="width: 100%">
        <center><img style="padding-top: 0%" width="100%" src="vid/RandGif.gif"></center>
        <div class="overlayText">
                <br>
            </div>
       
    </figure>
<<<<<<< HEAD
    </div>
        <!-- <br>
		<br>
	 -->
=======
</div>
<div class="overlayText">
                <center>
                <p id="topText"><font size="-1">Veloview point cloud data for an obstacle 1 m from the LiDAR with no EMI injection (left), EMI injection at the sinusoidal perturbation frequency (middle), and the EMI injection at the observed random perturbation frequency (right). The antenna is placed to the left of the LiDAR (it does not appear in the point cloud because it is too narrow).
</font></p>
>>>>>>> f4e6c6e64282d0486d6c93427d2a39356781cce8
	
    </section>

    <section id="outdoor"/>
	
		<br>
    <h2>Adversarial Capability and Modeling</h2>
    <hr>
    <div class="flex-row">
        <p>
            <br>
            To perform experiments for evaluation of the attacker's capabilities and synthesize perturbations, we use the following equipment: <br>
            &emsp;‚Ä¢ LiDAR model: <strong><a href="https://velodynelidar.com/products/puck/">VLP-16</a></strong> <br>
			&emsp;‚Ä¢ Point Cloud visualizer: Veloview <br>
            We characterize the attacker capability using the parameters described in the table below: 
        </p>
                   <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="50%" src="img/AdversaryParameterTable.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">Parameters used to characterize the capabilities of our adversary.</font></p>
            </center>
            </div>
       
    </figure>
            </figure>
            <br>
        <div class="flex-row">
            <br>
            <br>
            We found that the point cloud can be detectably perturbed above 1 m in the XY direction, but that the perturbation is less pronounced in the XZ direction:
            <div class="col-2 text-center"> <figure style="width: 100%">
        <center><img width="60%" src="img/SNRXY.png"></center>
        <div class="overlayText">
                <br>
                <p id="topText"><font size="-1">SNR vs distance between victim LiDAR and adversary in the XY plane.</font></p>
            </div>
       
    </figure>
    </div>
    <div class="col-2 text-center"> <figure style="width: 100%">
        <center><img width="60%" src="img/SNRXZ.png"></center>
        <div class="overlayText">
                <br>
                <p id="topText"><font size="-1">SNR vs distance between victim LiDAR and adversary in the XZ plane.</font></p>
            </div>
       
    </figure>
    </div>

            We found that the wavelength of the sinusoidal perturbation in both the XY and XZ planes are linearly related with the distance between the victim LiDAR and the target obstacle:
            <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="50%" src="img/XYtargetDistance.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">Sinusoidal pattern characterization wavelength with respect to ùëë<sub>O</sub> in the XY plane</font></p>
            </center>
            </div>
    </figure>
             <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="50%" src="img/XZtargetDistance.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">Sinusoidal pattern characterization wavelength with respect to ùëë<sub>ùëÇ</sub> in the XZ plane</font></p>
            </center>
            </div>
    </figure>
    <br>
    Furthermore, we found that the minimum affected angle was approximately 3 degrees and that the injected frequency affects the perturbation pattern. We also found that the mean displacement of the random perturbation and amplitude of the sinusiodal perturbation are linearly associated with the gain (associated with IEMI output power):

    <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="70%" src="img/DisplacementAmplitude.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">The effect of gain on the mean displacement for the random perturbation and the amplitude for the sinusiodal perturbation.</font></p>
            </center>
            </div>
       
    </figure>
    Based on the observed trends, we modeled the sinusoidal perturbation's amplitude and the random perturbation's mean displacement, maximum displacement, and minimum displacement in terms of gain. We model the sinusoidal perturbation wavelength in terms of distance between the victim LiDAR and the target obstacle.
        </div>
        
    </div>

        <!-- <div class="flex-row"> -->
            <!-- <div style="width: 50%; box-sizing: border-box; padding: 10px; margin: auto;"> -->
                
            <!-- </div> -->
     
<!--  -->
        <!-- </div> -->
        <!-- </div> -->



</section>

<section id="Evaluations"/>
<br>
<h2>Evaluations</h2>
<hr>
<div class="flex-row">
    <p>
        <br>
        We model perturbations using the empirically observed listed in the previous section. We then synthesize perturbations in the KITTI evaluation dataset to evaluate how perturbations affect PointRCNN and PointPillars. The previous experiments are limited at 25 dB gain due to safety concerns, so we extrapolate the effects of higher gain values. 

        <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="80%" src="img/synthesized_ptCloud.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">Illustration of a point cloud with no attack (left) with the corresponding random (middle) and sine (right) synthesized perturbations.
</font></p>
            </center>
            </div>
       
    </figure>




        
<h3 class="card-subhead">Object Misdetection and Misclassification</h3>
<div class="flex-row">
    We consider the object detection of an individual object successful if the corresponding prediction has an Intersection over Union (IOU) greater than the desired threshold with respect to the ground truth. Similarly, we consider object classification successful if the detected object is classified as the correct object class. We perform two different analyses based on the IOU threshold. In the first analysis, we set the IOU threshold to 0 (WIOU). Here, if the predicted object has an IOU with respect to the ground truth greater than 0, we consider it a successful prediction. In the second analysis, we evaluate based on the default IOU thresholds as proposed in the corresponding works of each model (DIOU). The table below shows object detection and classification results for PointPillars, PointRCNN, and Apollo models for WIOU and DIOU analyses with sinusoidal and random perturbations:
        <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="50%" src="img/ODRCLR70dB.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">ODR and CLR of LiDAR-based models on WIOU and DIOU for sinusoidal and random perturbations at 70dB gain.</font></p>
            </center>
            </div>
       
    </figure>
</div>
        <br>
	
		<div class="flex-row">
		
    <p>
	<br>
	<br>
		<br>
        <br>
        
We also study the effect of the perturbation angle ùúÉ on ODR for
the models:
    </p>
       <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="100%" src="img/detectionPedestrian.png"></center>
        <div class="overlayText">
                <br>
                <center>
               <!--  <p id="topText"><font size="-1">ODR and CLR of LiDAR-based models on WIOU and DIOU for sinusoidal and random perturbations at 70dB gain.</font></p> -->
            </center>
            </div>
       
    </figure>
    <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="100%" src="img/detectionCyclist.png"></center>
        <div class="overlayText">
                <br>
                <!-- <center>
                <p id="topText"><font size="-1">ODR and CLR of LiDAR-based models on WIOU and DIOU for sinusoidal and random perturbations at 70dB gain.</font></p>
            </center> -->
            </div>
       
    </figure>
    <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="100%" src="img/detectionCar.png"></center>
        <div class="overlayText">
                <br>
                <!-- <center>
                <p id="topText"><font size="-1">ODR and CLR of LiDAR-based models on WIOU and DIOU for sinusoidal and random perturbations at 70dB gain.</font></p>
            </center> -->
            </div>
       
    </figure>
</div>
</div>
</section>

<section id="fusion"/>
<h2>Sensor Fusion</h2>
<hr>
<div class="flex-row">
    <p>
        <br>
<<<<<<< HEAD
        Camera-LiDAR sensor fusion models extract features from each
of the sensors used and allow them to complement each other to improve the accuracy of 3D object detection.
We analyze the impact of IEMI perturbations on two popular camera-LiDAR sensor fusion architectures: <br>
&emsp;&emsp;1) <strong>Frustum-ConvNet (FC)</strong>: a cascaded semantic-level fusion model that creates
frustum-level features on the LiDAR point cloud from each region
proposal from the camera image. <br>
&emsp;&emsp;2) <strong>AVOD</strong>: <A></A> feature-level fusion model
that extracts feature maps from RGB images from cameras and BEV
images of the LiDAR individually and then combines them.
<br> <br>
       We consider ODR and CLR as a metric to
evaluate the effect of perturbations on sensor fusion models. We consider both DIOU thresholds (0.7 for car
and 0.5 for pedestrian and cyclist obstacles for both models) and WIOU thresholds for each model. For this analysis, we randomly select 500 objects
for each of the cyclist, pedestrian, and car classes from the KITTI dataset and synthesize the perturbations on LiDAR point clouds.
The resulting drop in detection (ODR) and classification (CLR) rates are shown below.

<br>

<!-- The figure below shows the classification rates
for the two sensor fusion models when injecting the sinusoidal and
random perturbations for pedestrian, cyclist, and car classes. The
perturbations drop the ODR below 50% for pedestrian and cyclist
object classes in AVOD and for pedestrian and cyclist object classes
in Frustum-ConvNet. The ODR for car object class in AVOD and
cyclist object class in Frustum-ConvNet show instead robustness
against the perturbations.
The CLR for both the models follows a similar trend as ODR
with a drop below 50% for pedestrian and for cyclist in AVOD. No other scenarios in Frustum-ConvNet show misclassifications,
indicating that the CLR remains the same as ODR. This happens
because the region proposals for object detection in the model come
from camera image data that is not perturbed by our injection. Our
results show a significant deterioration of the model performance on
pedestrian and cyclist obstacle classes in AVOD and pedestrian and
car obstacles in Frustum-ConvNet. Furthermore, the perturbation
signal generates new obstacles in the sensor fusion models. For
AVOD, the precision drops by a maximum of 0.43 to 0.33, and the
recall drops from 0.56 to 0.45. For Frustum-ConvNet, the precision
drops from 0.69 to 0.52 while the recall from 0.46 to 0.32. -->
=======
        For this analysis we randomly select 500 objects
for each of the cyclist, pedestrian, and car classes from the validation
set of the KITTI dataset. We consider ODR and CLR as a metric to
evaluate the effect of perturbations on sensor fusion models. Here,
we consider the default IOU thresholds for each model (0.7 for car
and 0.5 for pedestrian and cyclist obstacles for both models).
<br>
<br>
The figure below shows the classification rates
for the two sensor fusion models when injecting the sinusoidal and
random perturbations for pedestrian, cyclist, and car classes:
>>>>>>> f4e6c6e64282d0486d6c93427d2a39356781cce8

       <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="70%" src="img/fusion_results.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1"> Object Detection Rates for AVOD (left) and Frustum-
ConvNet (right). Results for 500 random samples per object
class with synthesized perturbations at 70 dB gain.</font></p>
            </center>
            </div>
       
    </figure>
    </p>
</div>
<<<<<<< HEAD


<!-- <h3 class="card-subhead">Speed variation</h3>
<div class="flex-row">
    <p>
	Without the attack, the victim AV is expected to accelerate to reach the preset speed (32 km/h) at 46 meters, then uniformly decelerate and stop before reaching the obstacle.
        In the graphs below we observe the AV's speed change at different attack start conditions for 5 and 10-degree attack angles respectively. Figures (a) and (d) show that, by starting the attack at varying distances from the target obstacle, the attacker can remove the target obstacles for different time periods (based on the size of the obstacles and the attack angles). Figures (b), (c), (e), and (f), show that, though the obstacle is only removed in a limited amount of time, it will cause the AV to accelerate and collide with the obstacles. This is because when the attack starts and the target obstacle is removed, the victim AV will accelerate to reach the preset speed. The graphs also represent the expected AV stopping position in the scenario with no attack, and the position of the obstacle (marked as AV collision).<br>
        <br>
    </p> -->
=======
>>>>>>> f4e6c6e64282d0486d6c93427d2a39356781cce8
</section>

<section id="real-world"/>
<h2>Real-World Scenario</h2>
<hr>
<div class="flex-row">
    <p>
        <br>
       We further conduct a proof-of-concept experiment to analyze the
<<<<<<< HEAD
impact of IEMI signal injection in a real-world scenario. We target pedestrian obstacle at 2, 4, and 6 m away from the
victim LiDAR in a static scenario.

=======
impact of IEMI signal injection in a real-world scenario.
<br>
For the physical world evaluation, we
use PiFiNet, an attentive pillar network-based model trained on
the JRDB dataset for pedestrian detection. The JRDB Dataset
is a large-scale multi-modal dataset collected from a social mobile
manipulator JackRabbot.
>>>>>>> f4e6c6e64282d0486d6c93427d2a39356781cce8

<br>

We test the PiFiNet model under our IEMI injection
with the target pedestrian obstacle at 2, 4, and 6 m away from the
victim LiDAR in a static scenario. We increment the
transmitted signal gain in 1 dB intervals and measure the IOU metric
of the predicted bounding box with respect to ground truth. We
repeat the experiment for frequencies corresponding to sinusoidal
and random perturbations. We limit the gain to 25 dB for safety.

<br>

The figure below shows the results of PiFiNet
for pedestrian object detection with EMI signal injection:

 <figure style="margin-top: 10px; margin-bottom: 10px;">
            <center><img width="60%" src="img/outdoor_results_2.png"></center>
        <div class="overlayText">
                <br>
                <center>
                <p id="topText"><font size="-1">  IOU of predicted pedestrian objects from PiFiNet at
2, 4, and 6 meters away from the VLP-16 LIDAR for sinusoidal
(left) and random (right) perturbation injection.</font></p>
            </center>
            </div>
    </p>
</div>
    </div>

</section>


<section id="Acknowledgments"/>
<h2>Acknowledgments</h2>
<hr>
<br>
<div class="flex-row">
    <p>
        This research was supported in part by the NSF CNS-1933208, CNS-2055123, and JSPS KAKENHI Grant Number 22H00519
    </p>
</div>
</section>
</body>
</html>
